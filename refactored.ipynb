{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'data_creation' has no attribute 'write_to_parquet_pd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20768\\79266640.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_creation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"dataset_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pq\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdata_creation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_to_parquet_pd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'data_creation' has no attribute 'write_to_parquet_pd'"
     ]
    }
   ],
   "source": [
    "#generate some test data and write it to parquet files\n",
    "\n",
    "import data_creation\n",
    "\n",
    "for num_rows in [10000,100000,1000000]:\n",
    "    for num_cols in range(2,20):\n",
    "        data = data_creation.generate_test_data(num_rows, num_cols, num_cols)\n",
    "        filename = \"dataset_\"+str(num_rows)+\"_\"+str(num_cols)+\".pq\"\n",
    "        data_creation.write_to_parquet_pd(data,filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some test data and write it to parquet files\n",
    "\n",
    "import data_creation\n",
    "\n",
    "for num_rows in [10000,100000,1000000]:\n",
    "    for num_cols in range(2,20):\n",
    "        data = data_creation.generate_test_data(num_rows, num_cols, num_cols)\n",
    "        filename = \"dataset_\"+str(num_rows)+\"_\"+str(num_cols)+\".pq\"\n",
    "        data_creation.write_to_parquet_pl(data,filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/dataset_1000000_10.pq',\n",
       " 'data/dataset_1000000_11.pq',\n",
       " 'data/dataset_1000000_12.pq',\n",
       " 'data/dataset_1000000_13.pq',\n",
       " 'data/dataset_1000000_14.pq',\n",
       " 'data/dataset_1000000_15.pq',\n",
       " 'data/dataset_1000000_16.pq',\n",
       " 'data/dataset_1000000_17.pq',\n",
       " 'data/dataset_1000000_18.pq',\n",
       " 'data/dataset_1000000_19.pq',\n",
       " 'data/dataset_1000000_2.pq',\n",
       " 'data/dataset_1000000_20.pq',\n",
       " 'data/dataset_1000000_3.pq',\n",
       " 'data/dataset_1000000_4.pq',\n",
       " 'data/dataset_1000000_5.pq',\n",
       " 'data/dataset_1000000_6.pq',\n",
       " 'data/dataset_1000000_7.pq',\n",
       " 'data/dataset_1000000_8.pq',\n",
       " 'data/dataset_1000000_9.pq',\n",
       " 'data/dataset_100000_10.pq',\n",
       " 'data/dataset_100000_11.pq',\n",
       " 'data/dataset_100000_12.pq',\n",
       " 'data/dataset_100000_13.pq',\n",
       " 'data/dataset_100000_14.pq',\n",
       " 'data/dataset_100000_15.pq',\n",
       " 'data/dataset_100000_16.pq',\n",
       " 'data/dataset_100000_17.pq',\n",
       " 'data/dataset_100000_18.pq',\n",
       " 'data/dataset_100000_19.pq',\n",
       " 'data/dataset_100000_2.pq',\n",
       " 'data/dataset_100000_20.pq',\n",
       " 'data/dataset_100000_3.pq',\n",
       " 'data/dataset_100000_4.pq',\n",
       " 'data/dataset_100000_5.pq',\n",
       " 'data/dataset_100000_6.pq',\n",
       " 'data/dataset_100000_7.pq',\n",
       " 'data/dataset_100000_8.pq',\n",
       " 'data/dataset_100000_9.pq',\n",
       " 'data/dataset_10000_10.pq',\n",
       " 'data/dataset_10000_11.pq',\n",
       " 'data/dataset_10000_12.pq',\n",
       " 'data/dataset_10000_13.pq',\n",
       " 'data/dataset_10000_14.pq',\n",
       " 'data/dataset_10000_15.pq',\n",
       " 'data/dataset_10000_16.pq',\n",
       " 'data/dataset_10000_17.pq',\n",
       " 'data/dataset_10000_18.pq',\n",
       " 'data/dataset_10000_19.pq',\n",
       " 'data/dataset_10000_2.pq',\n",
       " 'data/dataset_10000_20.pq',\n",
       " 'data/dataset_10000_3.pq',\n",
       " 'data/dataset_10000_4.pq',\n",
       " 'data/dataset_10000_5.pq',\n",
       " 'data/dataset_10000_6.pq',\n",
       " 'data/dataset_10000_7.pq',\n",
       " 'data/dataset_10000_8.pq',\n",
       " 'data/dataset_10000_9.pq']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_creation\n",
    "data_creation.get_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by pd.read_parquet(): 0.06301760673522949 seconds\n"
     ]
    }
   ],
   "source": [
    "#Let's poc style try to test one thing\n",
    "# save to parquet and load data using pandas\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start_time_pd_pq = time.time()\n",
    "\n",
    "\n",
    "#df.to_parquet(\"data_pd_pq.parquet\")\n",
    "df_loaded = pd.read_parquet(\"data/dataset_10000_10.pq\")\n",
    "\n",
    "end_time_pd_pq = time.time()\n",
    "\n",
    "time_taken_pd_pq = end_time_pd_pq - start_time_pd_pq\n",
    "\n",
    "# Print data and runtime\n",
    "print(f\"Time taken by pd.read_parquet(): {time_taken_pd_pq} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function test_read_pd took 17.638832807540894 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "from measure_wrappers import *\n",
    "import data_creation\n",
    "import pandas as pd\n",
    "\n",
    "@measure_runtime\n",
    "def test_read_pd():\n",
    "    for data_set_location in data_creation.get_all_datasets():\n",
    "      df_loaded = pd.read_parquet(data_set_location)\n",
    "\n",
    "test_read_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function test_read_pl took 4.647876977920532 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# save to parquet and load data using pandas\n",
    "# show table size !\n",
    "import polars as pl\n",
    "import data_creation\n",
    "from measure_wrappers import measure_runtime\n",
    "\n",
    "@measure_runtime\n",
    "def test_read_pl():\n",
    "    for data_set_location in data_creation.get_all_datasets():\n",
    "      df_loaded = pl.read_parquet(data_set_location)\n",
    "\n",
    "test_read_pl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function test_read_pl took 0.0029718875885009766 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# save to parquet and load data using pandas\n",
    "# show table size !\n",
    "import polars as pl\n",
    "from measure_wrappers import measure_runtime\n",
    "\n",
    "@measure_runtime\n",
    "def test_read_pl():\n",
    "    df_loaded = pl.read_parquet(\"data/dataset_10000_10.pq\")\n",
    "\n",
    "test_read_pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
